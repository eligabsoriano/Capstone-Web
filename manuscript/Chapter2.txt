UPANG-FA.pdf 

MSME PATHWAYS: SMART LOAN SUPPORT
FOR THE INFORMAL SECTOR






A Capstone Project Presented to the Faculty of the
College of Information Technology Education
PHINMA - University of Pangasinan




In Partial Fulfillment 
of the Requirements for the Degree
BACHELOR OF SCIENCE IN INFORMATION TECHNOLOGY




by
JUSTIN MC NEAL GONZALES CARONONGAN
ELI GABRIEL TAMONDONG SORIANO
JOHN LLOYD PIMENTEL 
FENIEL BARTE
JOSHUA CO


March 2026
Chapter 2
METHODOLOGY
This chapter discusses the methodology employed in developing the proposed system, MSME Pathways: Smart Loan Support for the Informal Sector. It presents the development methodology, system architecture overview, tools and technologies used, population and locale of the study, data gathering techniques, sources of data, treatment of data, and ethical considerations.


Development Methodology
This section explains the development methodology used in the study, including the selected software development model, the Scrum events followed by the team, and the corresponding sprint deliverables.
Software Development Model. The study employs the Agile Software Development Model using the Scrum approach. Scrum supports incremental delivery through short development cycles, enabling the research team to prioritize features, validate requirements, and continuously improve system components based on stakeholder feedback. This model is suitable for MSME Pathways because the system includes complex and interdependent features such as AI-enabled guidance and profiling, as well as blockchain-based transaction integrity mechanisms that require iterative refinement and staged integration.
The Scrum approach is appropriate for the project scope because it encourages frequent feedback and progressive enhancement of system functionality and usability. In the context of informal-sector microentrepreneurs, user needs and constraints (e.g., limited time, varying digital literacy, and practical concerns during lending interactions) are better addressed through repeated validation of interface design, content clarity, and guidance accuracy. Scrum also supports risk reduction by enabling early testing of high-impact modules such as the AI chatbot and profiling logic, while allowing blockchain components to be integrated and verified gradually to ensure system stability and reliability.
Within the study, the researchers functioned as the development team and coordinated with advisers and stakeholder representatives for requirement validation and sprint feedback. The Product Backlog served as the main artifact for organizing priorities, while each sprint produced an increment that was reviewed for completeness and academic relevance. In this study, design, development, testing, and deployment are treated as engineering activities performed within each sprint, not as formal Scrum phases.


Figure 1 presents the software development model adopted in the study, illustrating the flow of activities involved in system development.
Figure 1
Scrum Events and Sprint Activities
(Insert Figure 1 here. All images will be applied with a thin, gray border.)
Product Backlog and Backlog Refinement. The team translated interview findings, survey inputs, and system requirements into user stories and prioritized backlog items. Backlog refinement was conducted regularly to clarify acceptance criteria, re-estimate effort, and re-order priorities based on technical feasibility and stakeholder feedback. Deliverables included an updated Product Backlog, requirement mapping notes, and sprint-ready stories.
Sprint Planning. At the start of each sprint, the team selected the highest-priority backlog items and defined a clear sprint goal aligned with research objectives. Planning outputs also included task decomposition, dependency identification, and assignment of implementation targets for frontend, backend, AI, and blockchain-related tasks. Deliverables included the Sprint Backlog, sprint goal statement, and implementation task list.
Sprint Execution (with Daily Scrum). During sprint execution, the team held short daily coordination sessions to report progress, identify blockers, and synchronize work. Core engineering activities were performed within the sprint, including interface design refinement, feature development, API integration, validation checks, and defect fixing. Outputs included working increments of mobile/web modules, backend services, AI functions, blockchain components, and corresponding test and issue records.
Sprint Review. At the end of each sprint, completed increments were demonstrated to advisers and stakeholder representatives for functional and usability validation. Feedback from the review was documented and converted into backlog updates for the next sprint cycle to ensure continuous alignment with user and study requirements. Deliverables included sprint review notes, accepted increments, and change requests.
Sprint Retrospective. After the review, the team conducted a retrospective to evaluate what worked well, what problems occurred, and what process improvements were needed. Agreed improvement actions were carried forward to the next sprint to improve workflow efficiency, quality control, and collaboration. Deliverables included retrospective findings and actionable process improvement items.
Release and Deployment Preparation. After iterative sprint cycles, the team consolidated validated increments and prepared the prototype for controlled release and demonstration. Activities included environment configuration, final integration and regression checks, documentation completion, and readiness verification for academic evaluation. Deliverables included the prototype build, user guide/manual, deployment notes, and demonstration checklist.


System Architecture Overview
The proposed system follows a three-tier architecture consisting of the presentation layer, application layer, and data layer. This architecture enforces separation of concerns so that user interaction channels, business logic, and data services can evolve independently while remaining integrated through secure APIs.
        Presentation Layer. The presentation layer includes a Flutter-based mobile application for informal-sector microentrepreneurs and a web dashboard for loan officers and administrators. The mobile application supports onboarding, guidance access, profiling inputs, and loan-readiness interactions, while the web dashboard supports monitoring, application review, decision support, and reporting workflows.
        Application Layer. The application layer is implemented using Python Django and Django REST Framework as the central service orchestration layer. It manages authentication and role-based access, profile and document handling, AI-enabled chatbot and profiling logic, loan pre-qualification and lifecycle workflows, notifications, analytics, and blockchain transaction coordination through backend service integration.
        Data Layer. The data layer consists of MongoDB Atlas for operational data storage, document storage services for uploaded files, and Ethereum smart contracts for tamper-resistant integrity records. MongoDB Atlas stores user, profile, loan, interaction, and audit data, while blockchain records are used for immutable verification references. Sensitive personal data remain off-chain, and only integrity-relevant references are written to blockchain.
Figure 2
Three Tier Architecture
```mermaid
flowchart TB
  subgraph PL[Presentation Layer]
    M[Flutter Mobile Application]
    W[Web Dashboard]
  end

  subgraph AL[Application Layer - Django REST]
    API[API Gateway]
    CORE[Core Services: Auth, Profiles, Documents, Loans, Analytics, Notifications]
    AIM[AI Module: Chatbot and Profiling]
    BCM[Blockchain Module]
  end

  subgraph DL[Data Layer]
    MDB[(MongoDB Atlas - Operational Data)]
    DS[(Document Storage)]
    ETH[(Ethereum Smart Contracts - Integrity Records)]
  end

  M --> API
  W --> API
  API --> CORE
  CORE --> AIM
  CORE --> BCM
  CORE --> MDB
  CORE --> DS
  BCM --> ETH
```
Tools and Technologies Used
The development of the proposed system utilizes the following tools and technologies:
Programming Languages. Python is used for backend services, API processing, and business logic orchestration. TypeScript and JavaScript are used for frontend web development to improve maintainability and type-safe component integration. Dart is used for the Flutter mobile application (assumed integrated mobile codebase) to support cross-platform deployment. Solidity is used for Ethereum-compatible smart contract development for integrity and audit-related transaction records.
Frontend Technologies and Libraries. The web interface is developed using React and React DOM, with routing through React Router DOM. State and asynchronous data handling use TanStack React Query, TanStack React Table, Axios, and Zustand to support responsive dashboards and workflow-driven views. Form and validation components use React Hook Form, @hookform/resolvers, and Zod to enforce structured user input. UI and interaction libraries include Radix UI components (alert-dialog, avatar, dialog, dropdown-menu, label, select, slot, tabs, tooltip), Tailwind CSS, @tailwindcss/vite, tailwind-merge, class-variance-authority, clsx, Framer Motion, Lucide React, Recharts, Sonner, React Error Boundary, and date-fns. These technologies collectively support usability, accessibility, and visual consistency required for role-based loan management interfaces.
Backend Frameworks and Libraries. The backend is implemented using Django, Django REST Framework, and django-cors-headers to deliver secure RESTful services across client platforms. Data access and utility support include PyMongo and dnspython for MongoDB connectivity. Authentication and security components include djangorestframework-simplejwt, PyJWT, and bcrypt. Two-factor authentication and OTP-related components use pyotp, qrcode, and Pillow. API integrations use requests. Background processing tools include Celery, django-celery-beat, and Redis for scheduled and asynchronous tasks. Environment and runtime support use python-dotenv, pytz, certifi, python-dateutil, asgiref, WhiteNoise, and Gunicorn.
AI and Machine Learning Technologies. AI guidance and conversational responses are integrated through the Groq API service to support user education and decision-support interactions. Document-analysis model tooling includes PyTorch (torch), torchvision, and OpenCV (opencv-python) for CNN-based workflows related to document verification and classification. These technologies support the study objective of AI-enabled loan guidance and profiling assistance.
Blockchain Technologies. Smart contracts are implemented in Solidity and are developed, compiled, tested, and deployed using Hardhat within the backend smart contract module (`backend/smartcontracts`). The blockchain toolchain includes @nomicfoundation/hardhat-toolbox, @nomicfoundation/hardhat-verify, @openzeppelin/contracts, @openzeppelin/contracts-upgradeable, and @openzeppelin/hardhat-upgrades, with code quality support from solhint, prettier, and prettier-plugin-solidity. This stack supports transparent, tamper-resistant recording of integrity-relevant events.
Database and Storage. MongoDB Atlas is used as the primary cloud-based NoSQL database for user, profile, application, interaction, and audit records. Document files are stored through the system document storage layer, while blockchain outputs are stored as integrity references on Ethereum-compatible networks. This arrangement keeps sensitive personal information off-chain while preserving auditability for critical transactions.
Testing and Quality Assurance Tools. Frontend unit and component testing use Vitest, @vitest/ui, @vitest/coverage-v8, jsdom, @testing-library/react, @testing-library/jest-dom, and @testing-library/user-event. End-to-end testing uses Playwright to validate cross-page behavior and role-based workflows. Code quality enforcement uses Biome, Husky, and lint-staged to maintain consistent coding standards and reduce integration defects.
Build, Deployment, and Runtime Tools. Frontend build and development use Vite (Rolldown-Vite) and @vitejs/plugin-react for fast iteration and optimized production builds. Backend deployment uses Gunicorn with Procfile-based process definition and Python runtime configuration. Background scheduling uses Celery Beat with Redis broker/backend support, enabling periodic maintenance and operational automation.
Development and Collaboration Tools. Visual Studio Code (VS Code) is used as the primary development environment across frontend, backend, AI, and blockchain modules. Git and GitHub are used for source control, collaboration, and revision traceability throughout Scrum iterations. Insomnia and/or Postman are used for API endpoint testing and integration verification during development and testing phases.


Population and Locale of Study
The population of the study consists primarily of informal-sector microentrepreneurs in Dagupan City, particularly sari-sari store owners, market vendors, and similar small-scale operators who represent the intended end users of the MSME Pathways platform. These respondents are included because they directly experience the financial access barriers identified in Chapter 1 and can provide grounded feedback on usability, clarity of guidance content, and relevance of loan-readiness features.
As supporting respondents, selected loan officers and lending personnel are included to evaluate the operational usefulness of the web dashboard, profiling outputs, and pre-screening support functions. Their participation provides practitioner insight on whether the system outputs are understandable and applicable to preliminary lending workflows within the prototype scope.
Respondents are selected through purposive sampling based on role relevance, willingness to participate, and accessibility during the data-gathering period. This sampling approach ensures that participants are directly connected to the functional objectives and evaluation criteria of the study.
The locale of the study includes PHINMA-University of Pangasinan and selected barangays in Dagupan City. System development, configuration, and controlled technical testing are conducted within the university environment, while requirement validation and usability feedback are collected from selected community areas where target microentrepreneurs regularly operate.


Data Gathering Techniques
Data gathering techniques are used to obtain requirement-level insights and evaluation feedback from intended users and supporting stakeholders. The study applies a mixed set of qualitative and quantitative techniques to ensure that both contextual realities and measurable usability outcomes are captured.


Interviews. Semi-structured interviews are conducted with informal-sector microentrepreneurs to collect direct insights on borrowing behavior, lending-related difficulties, information gaps, and preferred support mechanisms. An interview guide is used to maintain consistency across respondents while allowing follow-up probing questions. Interview results are documented and reviewed to identify recurring themes that inform feature prioritization, content simplification, and workflow design.


Survey Questionnaires. Structured survey questionnaires are administered (e.g., via Google Forms) to gather quantifiable feedback on usability, clarity, usefulness, and user satisfaction after prototype interaction. The questionnaire focuses on indicators such as ease of navigation, understandability of financial guidance, perceived relevance of recommendations, and confidence in using the system. Results are summarized using descriptive statistics to support refinement decisions.


Observation. Non-participant observation is conducted to understand existing lending-related practices and informal borrowing workflows in the target context. Observation notes capture process patterns, communication behaviors, and environmental constraints that may affect real-world system adoption. These findings are used to validate whether the proposed interfaces and process flow remain realistic and context-appropriate.


Data Triangulation. Findings from interviews, survey responses, and observation records are cross-checked to improve consistency and credibility of conclusions. Convergent findings are used as priority inputs for system refinement, while conflicting findings are reviewed in follow-up discussions before implementation decisions are finalized.




Sources of Data
Data is one of the most important elements in every research study because the validity of findings depends on the quality and relevance of collected information. For this study, data are gathered from primary and secondary sources to ensure that system design and evaluation are grounded in both real stakeholder context and established references.


Primary Sources. The primary sources of data are the selected respondents who directly interact with, evaluate, or manage the proposed system.
Informal-sector Microentrepreneurs. This group serves as the main respondent population because they are the intended beneficiaries of the proposed mobile application. Their responses provide requirement-level insights and usability feedback on financial guidance, profiling inputs, and loan-readiness support.
Loan Officers/Lending Personnel. This group serves as supporting respondents for evaluating the practicality of profiling outputs, dashboard functions, and pre-screening support workflows used in lending-related tasks.
System Administrators. This group serves as supporting respondents for evaluating administrative controls, monitoring features, and role-based management functions in the web dashboard.


Table 1
Respondents of the Study


Respondent Group                  No. of Respondents
Informal-sector Microentrepreneurs [To be finalized]
Loan Officers/Lending Personnel    [To be finalized]
System Administrators              [To be finalized]
Total                              [To be finalized]


Secondary Sources. Secondary data are obtained from published studies, government and institutional reports, and technical references related to microfinance, financial inclusion, AI-assisted decision support, and blockchain-enabled auditability. These include relevant Bangko Sentral ng Pilipinas (BSP) resources, financial inclusion publications, and sample lending forms and workflow references. Secondary sources are used to support requirement justification, contextualize respondent findings, and align the study with existing academic and industry practices.


Treatment of Data
The treatment of data describes how the information gathered in the study is handled after collection to ensure accuracy, consistency, and data security throughout the project.


Data Collection. Data were collected from user and respondent inputs within the system and study instruments, including registration details, profile entries, loan-related submissions, and feedback during prototype use. Additional data were obtained from interview notes, survey responses, observation records, and relevant system/database records. Where applicable, API-based exchanges between client applications and backend services were used to capture and transmit required data inputs.


Data Processing. The collected data were reviewed, organized, and cleaned to ensure completeness and consistency. Data from different sources were standardized into uniform formats (e.g., field structure, naming conventions, and input format rules) before further use. Validation rules were applied to minimize incomplete, duplicate, or inconsistent entries.


Data Analysis. Descriptive analysis techniques were applied to summarize user responses and system data for system refinement and evaluation. For AI-supported features, machine-learning-based processing was used within the system to generate guidance-oriented outputs and profiling support, while interpretation of study findings remained focused on usability, functionality, and requirement alignment.


Data Storage and Backup. All collected data were stored securely in MongoDB Atlas and related system storage components with restricted access controls. Backup measures, including scheduled database backups and recovery procedures, were implemented to prevent data loss and maintain data availability during system operation. Integrity-related references were also recorded in blockchain components to support auditability.


Ethical Consideration
Ethical consideration guides the development and implementation of the proposed system to ensure responsible use of technology, protection of user data, inclusivity of design, and transparent communication to end users. The study adheres to ethical principles related to data security and privacy, fairness in system behavior, and responsible use of AI-enabled outputs.


Security and Privacy of Data. The study applies security measures to safeguard sensitive information collected from respondents and system users. Access to data is restricted through role-based access controls for multi-user functions, while authentication safeguards include password hashing, token-based session control, and two-factor verification for protected accounts. Data transmission and storage are handled using secure configurations appropriate for the prototype environment. Interview and survey records are treated confidentially, and reporting uses aggregated or non-identifying summaries to protect respondent privacy.


Fair and Inclusive Design. The system is designed to support users with diverse needs and varying levels of digital literacy. Interfaces are structured with simple workflows, clear labels, and readable content to improve accessibility across mobile and web usage contexts. Guidance content is written in practical, understandable language, and AI-supported profiling outputs are treated as decision-support indicators rather than deterministic judgments. The study also emphasizes continuous review of prompts, rules, and outputs to reduce bias and improve fairness for underserved users.


